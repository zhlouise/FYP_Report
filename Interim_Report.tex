\documentclass[12pt, a4paper]{article}


% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times} % Sets font to Times New Roman
\usepackage[margin=2.5cm]{geometry} % Sets 2.5cm margins
\usepackage{setspace} % Required for double spacing
\usepackage{titlesec}
\usepackage{sectsty}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{soul}
\usepackage{color}
\usepackage{amsmath}
\usepackage{float}


% --- Settings ---
\doublespacing % Applies double spacing to the document
\sectionfont{\normalsize}
\subsectionfont{\normalsize\it\bfseries}
\subsubsectionfont{\normalsize\it}


\begin{document}


% --- Title Page ---
\begin{titlepage}
    \centering
    \includegraphics[width=0.5\textwidth]{Included_Images/PolyU_Logo.png}
    \hfill
    \includegraphics[width=0.25\textwidth]{Included_Images/FENG_Logo.png}
    \vfill
    {\Large 2025/26 Interdepartmental Final Year Project Interim Report\par}
    {\huge \textbf{Intelligent UAV Systems for GNSS-Based Remote Sensing on
    Vegetation} \par}
    \vfill
    {\large [AAE] ZHOU Jiayi (22099961D) \par} {\large [AAE] MAHMUD Md Sahat
    (22097159D) \par} {\large [EEE] GAMAGE Sashenka (22097129D) \par} {\large
    [ME] TAN Qing Lin (22101126D) \par}
    \vfill
    {\large \textbf{Chief Supervisor: } [AAE] Prof. Guohao ZHANG \par} {\large
    \textbf{Co-Supervisor: } [AAE] Prof. Li-Ta HSU \par}
    \vspace{1cm}
    {\large \textbf{Date of Submission: } 2026 January 18 \par}
\end{titlepage}


% --- Table of Contents ---
\pagenumbering{roman}
\tableofcontents
\newpage


% --- Main Content ---
\pagenumbering{arabic}


% --- Abstract ---
\section{Abstract}
Placeholder text


% --- Introduction ---
\section{Introduction}
Vegetation is a critical asset to the environment and the human civilization.
Not only does vegetation produce essential societal resources, but its
distribution and productivity also greatly impacts the terrestrial ecosystems
and the global climate \cite{Richardson2013}. Therefore, the continuous and
accurate monitoring of vegetation is essential for sustainable resource
management \cite{Wallace2006}, ecosystem preservation \cite{Zeng2022}, and
climate change modeling \cite{Richardson2013}. 

Traditionally, methods of vegetation monitoring involved manual field
assessments of site characteristics, extracting vegetation condition indicators
such as species composition, geometrical structure, and biochemical activities
\cite{Gibbons2006}. However, the accuracy and efficiency of such monitoring
methods are highly dependent on the available expertise and resources, as the
site assessments often required the assessor to possess reasonable levels of
field knowledge prior to surveying \cite{Parkes2003}. To address the limitations
of manual assessments and to accommodate for the increasing large-scale
monitoring demands, remote sensing systems emerged as an essential tool for
ecological monitoring \cite{Li2023}. 

Remote sensing refers to the acquisition of an object's information through
measurements obtained without coming into direct contact with said object,
effectively minimizing the need for manual involvement on-site
\cite{campbell2011introduction}. Specifically, remote sensing relies on
information derived from different measurements of energy reflected from the
object of interest \cite{campbell2011introduction}. In the context of surveying
terrestrial vegetation, the remote sensing methods could be classified into two
categories based on the distance between the target object and the measurement
sensor: 1) space-borne and 2) airborne remote sensing. Space-borne remote
sensing involves the use of instruments onboard orbiting satellites, including
spectral and hyperspectral cameras \cite{Qian2022}, synthetic aperture radar
(SAR) \cite{Hu2025}, and space-borne Light Detection And Ranging (LiDAR) sensors
\cite{Bergen2009}. Due to the wide coverage and availability of space-borne
data, large-scale terrestrial changes over time could be captured, enabling the
continuous monitoring of macro-scale ecosystems \cite{Khan2024}. Compared to
space-borne systems, airborne remote sensing can provide significantly improved
spatial resolution and assessment flexibility through the integration of sensors
onboard manned aircraft or unmanned aerial vehicles (UAVs) \cite{Khan2024}.
Although limited by coverage area, airborne remote sensing can provide timely
information for addressing regional emergencies such as pest \cite{Wulder2006}
or wildfire \cite{Arroyo2008} outspreads since the systems could be deployed
on-demand. In UAV-based remote sensing particularly, this temporal flexibility
is further complemented with the benefit of low operational cost, rendering it
an ideal platform for monitoring regional and urban vegetation \cite{Tang2015}. 

Conventionally, UAV remote sensing platforms carry similar instruments to that
of other remote sensing systems, including radar, LiDAR, and multi-spectral or
hyperspectral imagery sensors \cite{Tang2015}. However, while imaging
instruments are susceptible to the influence of lighting and weather
\cite{Wu2024}, LiDAR devices tend to face difficulties penetrating through dense
canopy \cite{Su2007}. Therefore, it is critical to explore a robust sensing
technique that is suitable for UAVs in terms of payload and power consumption to
complement the existing instruments. Recently, the technique of Global
Navigation Satellite System Reflectometry (GNSS-R) is receiving increasing
interest in the field of remote sensing. GNSS-R exploits the L-band signals
transmitted from Global Navigation Satellite Systems (GNSS) that are then
scattered on different terrain surfaces of the Earth \cite{Jin2024}. Then, the
reception of reflected GNSS signals can provide information regarding the
properties of the signal reflector on land \cite{Jin2024}. As signals of
opportunity conventionally dedicated to Positioning, Navigation, and Timing
(PNT) applications, GNSS is capable of providing real-time measurements
regardless of time, location, and weather \cite{Jin2024}. Additionally, as a
bi-static system where signal transmitters are separated from receivers, GNSS-R
is exempt from the need of dedicated transmitter-receiver instruments that are
crucial to mono-static radar systems \cite{Jin2010}. Instead, any consumer-grade
receivers capable of receiving reflected GNSS signals could be used for GNSS-R
remote sensing, further demonstrating GNSS-R's applicability onboard low-cost
remote sensing systems such as an UAV. 

\hl{May need some intro for path planning and lidar here. The above is from
Louise's project proposal, so need further editing. (Also need to mention 
the full name of SLAM somewhere)}

In this project, the technique of GNSS-R will be integrated onto an UAV platform
to achieve an intelligent and structured remote sensing system for vegetation
monitoring. The main objectives of this project are as follows:
\begin{enumerate}
\item To introduce an autonomous path planning framework onboard the UAV platform
for optimized GNSS-R remote sensing.
\item To analyze and model the correlations between signal propagation parameters
retrieved through GNSS-R and ground vegetation conditions.
\item To classify signals reflected by vegetation and predict vegetation parameters
based on raw GNSS data using machine learning-based approach.
\item To establish a detailed 3D canopy map using LiDAR-based SLAM, providing a
spatial validation reference for the 2D vegetation features detected by GNSS-R.
\end{enumerate}

This report is structured as follows: Section 3 reviews contemporary research in
UAV path planning, GNSS-R, machine learning, and LiDAR SLAM, while Section 4
outlines the project's methodologies. The subsequent sections cover the
experiments conducted (Section 5), a discussion of current results (Section 6),
and the project conclusions (Section 7). Finally, Section 8 explores future
work, and Section 9 summarizes project management details. 


% --- Literature Review ---
\section{Literature Review}
To achieve the project objectives, this literature review comprehensively examines
the contemporary research in four domains, each associated with one project objective.
\hl{First, existing path planning methodologies are reviewed to \dots}
Subsequently, the existing techniques of GNSS-R are explored, with a focus on its
prior applications in vegetation parameter retrieval. 
\hl{Then, machine learning \dots}
\hl{Finally, LiDAR-based SLAM techniques \dots}
Consequently, this review identifies the existing gaps in each domain for the 
objective of vegetation monitoring, which will inform the integrated project 
methodologies.

\subsection{Path Planning}
Placeholder text

\subsection{GNSS-R}
The concept of using GNSS-R for remote sensing was first proposed in 1993, where
the correlation between direct and scattered GNSS signals were proven promising
for the application of ocean altimetry \cite{MartnNeira1993APR}. Today, apart
from the originally proposed application, GNSS-R techniques has been extensively
used for Earth observations and land information retrieval, including ocean
salinity, soil moisture, and ice thickness \cite{RodriguezAlvarez2011}. However,
research on vegetation parameter retrieval remains limited to preliminary
analyses \cite{Jia2018}. 

In a previous study, the capabilities of monitoring vegetation through GNSS-R
were demonstrated through a theoretical simulation of GNSS scattering
characteristics \cite{Ferrazzoli2011}. Furthermore, this study revealed that the
sensitivity of GNSS-R signals can be influenced by incidence angle, soil
parameters, and tree size, while signals with lower elevation angles and RL
polarization (transmission of right-hand circular polarization (RHCP) signal,
reception of left-hand circular polarization (LHCP) signal) appeared to be ideal
for forest monitoring \cite{Ferrazzoli2011}. In another study, the polarization
scattering properties of GNSS-R signals in forest canopies were modeled, where
simulations revealed that tree trunk scattering effects would dominate total
scattering response, while satellite azimuth angles are significantly correlated
to the signal polarization \cite{Wu2014}. 

Aside from simulated approaches, empirical or semi-empirical studies regarding GNSS-R
remote sensing of vegetation were also reviewed. In a study by Yueh et al.,
GNSS-R data onboard the Cyclone GNSS (CYGNSS) satellite were analyzed against
the vegetation water content estimated through the satellite-derived Normalized
Difference Vegetation Index (NDVI) \cite{Yueh2022}. The results demonstrated
near-linear relationship between vegetation water content and GNSS-R signal
attenuation, while the CYGNSS data also suggested the existence of volume
scattering within complex forest components \cite{Yueh2022}. Similarly, another
study analyzing GNSS-R data from TechDemoSat-1 demonstrated reduced sensitivity
to soil moisture retrieval due to vegetation attenuation, which could be
effectively compensated using NDVI data, indicating a correlation between signal
attenuation and vegetation water content \cite{Camps2016}. Additionally, the
interference pattern between direct and reflected GNSS signals from the Earth's
surface was used in estimating vegetation height and land topography
\cite{RodriguezAlvarez2011}. Through using a Soil Moisture Interference-pattern
GNSS Observations at L-band (SMIGOL) reflectometer, the instantaneous power of
the direct and reflected signals were coherently added, in which the resulting
power oscillations present notches that are correlated to vegetation layer
thickness and the reflection geometry \cite{RodriguezAlvarez2011}. As a result,
an RMSE of 3-5 cm in estimating the height of vegetation with simple geometrical
structures (barley and wheat) could be achieved \cite{RodriguezAlvarez2011}.
Yet, despite the effort in prior studies, the use of GNSS-R techniques in
vegetation remote sensing and monitoring is far from developed. Most
importantly, existing research relies heavily on space-borne or static
ground-based platforms, while the use of high spatial resolution and flexibility
platforms - such as an UAV - remains underexplored. Therefore, it is critical to
develop a systematic framework for an UAV-based GNSS-R system, in which
correlations between GNSS-R signal features and vegetation condition parameters
are comprehensively assessed and modeled. Additionally, with adequate dataset size,
the GNSS-R framework could be complemented by machine learning-based modelling
approaches, further enhancing the system robustness. \hl{Connection to ML part}

\subsection{Machine Learning}
Placeholder text

\subsection{LiDAR SLAM}
Placeholder text


% --- Methodology ---
\section{Methodology}
Placeholder text

\subsection{UAV Platform}
Placeholder text

\subsection{System Architecture}
Placeholder text

\subsection{Path Planning}
Placeholder text

\subsection{GNSS-R}
The GNSS-R framework takes in raw GNSS data collected from the onboard receivers
and runs the data through the steps of GNSS measurement extraction, Fresnel zone
analysis, and GNSS measurement level modelling. 

\subsubsection{GNSS Measurement Extraction}
Two major GNSS measurements are extracted from the collected data: carrier to
noise ratio ($C/N_0$) and pseudorange error. 

\paragraph{Carrier to Noise Ratio} ~\\
Carrier to noise ratio refers to the power of received carrier signal relative
to the noise power per unit bandwidth, usually expressed in decibel-Hertz (dB-Hz)
\cite{joseph2010gnss}. $C/N_0$ can be readily obtained from the receiver, and it 
is calculated using the following equation:
\begin{equation}
    C/N_0 = C - (N - BW)
\end{equation}
where $C$ refers to the carrier power in dBm or dBW; $N$ refers to the noise power
in dBm or dBW; and $BW$ refers to the bandwidth of the observation in Hz.

\paragraph{Pseudorange Error} ~\\
In GNSS, pseudorange refers to the "apparent" distance between a satellite and a
receiver, which includes the true geometric range plus various biases and delays.
For the $i$th satellite, its pseudorange $\rho^i$ could be expressed as the following 
\cite{kaplan2017understanding}:
\begin{equation}
    \rho^i = R^i + \Delta t_r + \Delta t_s^i + I^i + T^i + \epsilon^i
\end{equation}
where $R^i$ refers to the true geometric distance between the satellite and the receiver;
$\Delta t_r$ refers to the receiver clock bias; $\Delta t_s^i$ refers to the satellite
clock bias; $I^i$ refers to the ionospheric delay; $T^i$ refers to the tropospheric 
delay; and $\epsilon^i$ refers to the pseudorange error, which is mainly
introduced through signal reflections. Among all the signals received at a given
instant, a satellite $m$ with the highest elevation angle is selected as the
master satellite, where the assumption that the master satellite is free of reflections
is applied \cite{hsu2018analysis}:
\begin{equation}
    \rho^m = R^m + \Delta t_r + \Delta t_s^m + I^m + T^m.
\end{equation}
Assuming $\Delta t_s^i$ and $\Delta t_s^m$ can be effectively removed by 
satellite-broadcasted parameters, $I^i$ and $I^m$ can be effectively removed by the
Klobuchar model, and $T^i$ and $T^m$ can be effectively removed by the Saastamoinen model,
the pseudorange equations can be approximated as \cite{kaplan2017understanding}:
\begin{equation}
    \rho^i = R^i + \Delta t_r + \epsilon^i,
\label{ith satellite pseudorange}
\end{equation}
\begin{equation}
    \rho^m = R^m + \Delta t_r.
\label{master satellite pseudorange}
\end{equation}
Finally, taking the difference between \eqref{ith satellite pseudorange} and 
\eqref{master satellite pseudorange} and rearranging the equation will result in the
pseudorange error:
\begin{equation}
    \epsilon^i = \rho^i - \rho^m - R^i + R^m.
\end{equation}

\subsubsection{Fresnel Zone Analysis}
Placeholder text

\subsubsection{GNSS Measurement Level Model}
Placeholder text

\subsection{Machine Learning}
Placeholder text

\subsection{LiDAR SLAM}
\subsubsection{LiDAR-Inertial Odometry}
For the front end of the modular SLAM system, LiDAR-Inertial Odometry (Fast-LIO)
is used to build a map effectively within a short amount of time. To do this,
Iterative Extended Kalman Filter (IEKF) is used to fuse the data between IMU and LiDAR
point clouds to create an odometry of the environment. 

Iterative Extended Kalman Filter (IEKF) follows the core of Bayesian Recursion
to estimate the state of the robot through the prediction and measurement update
step. In the prediction step, IEKF assumes that the state of the system at time
$k$ evolved from the prior state at time $k-1$ is shown as follows:
\begin{equation}
    x_k = f(x_{k-1}) + w_{k-1} 
\end{equation}

Where $x_k$ is the state vector containing the terms of interest for the system
at time $k$. The $f(.)$ represents a non-linear state function that is used to
forecast current state data from prior state data. We can approximate $w_{k-1}$ as
$N(0,Q_k)$ where it has a zero-mean Gaussian distribution with covariance matrix
$Q_k$.

To know the uncertainty of the prediction model, error covariance matrix $P^f_k$
is defined as shown:
\begin{align}
    P_k^f &= E\left(e_k^f(e_k^f)^T\right) \nonumber \\
    &\approx F_k E(e_{k-1}e_{k-1}^T)F_k^T + E(w_{k-1}w_{k-1}^T) \nonumber \\
    &= F_kP_{k-1}F_k^T + Q_{k-1}
\end{align}

Where $e$ is the prediction error, $F$ is the Jacobian matrix of the linearized
state transition function $f(.)$ evaluated at the previous estimate
$x_{k-1}$, and $Q$ is the process noise covariance matrix representing the
uncertainty of the physical model.

Even so, the predicted state alone is prone to errors due to various
factors such as inaccurate prediction function and further source of noise. This
issue can be solved by taking sensor measurements to improve the predicted state
accuracy. Hence the observation model is defined as shown:
\begin{equation}
    z_k = h(x_k) + v_k
\end{equation} 

Where $z_k$ represents the expected sensor measurements based on the predicted
state $x_k$ expressed by a non-linear function $h(.)$, and the observation noise
$v_k$ is assumed as $N(0,R_k)$ where it has zero mean with covariance matrix $R_k$.

To further improve the accuracy for the nonlinear system, an iteration index
$K$ is added to repeat the measurement update at time step $k$ as shown:
\begin{equation}
    x^a_{k,K=0} = x^f_k
\end{equation}

Where $x^a$ is the state estimate after corrected by sensor measurement and
$x^f$ is the predictive distribution before looking at the lidar data. In this
case, the iteration $K$ is repeated until the change in the state estimate
$|x^a_{k,K+1} - x^a_{k,K}|$ falls below threshold $\epsilon$. 

As actual measurements from sensors will typically differ from this prediction
due to sensor noise and model inaccuracies, it is incorporated into the state
estimate by computing the difference between the actual measurements and the
predicted measurement based on the current iterative estimate $K$:
\begin{equation}
    z_{k, K} = z_k - h(x^a_{k, K})
\end{equation}
Where $h(x^a_{k, K})$ is the non-linear observation function evaluated at the
most recent estimate. To balance the uncertainty of the prediction against the
new sensor data, the Kalman Gain $K_{k,K}$ is calculated using the state-space
dimension formula \cite{xu2021fast}.
\begin{equation} 
    K_{k, K} = (H_{k, K}^T R_k^{-1} H_{k, K} + (P_k^f)^{-1})^{-1} H_{k, K}^T R_k^{-1} 
\end{equation}

Where $H_{k, K}$ is the Jacobian of the observation function re-evaluated
at the current iterative estimate $x^a_{k, K}$. This gain is then used
to compute the next refined state estimate:
\begin{equation}
    x^a_{k,K+1} = x^a_{k, K} + K_{k, K} (z_{k, K}) - (I - K_{k, K} H_{k, K})(x^a_{k, K} - x_k^f)
\end{equation}

After updating the state estimate, the updated covariance of the state
distribution is given as:
\begin{equation} 
    P_k = (I - K_{k, K} H_{k, K}) P_k^f 
\end{equation}

While the IEKF provides a high-frequency estimate of the current state, the
overall SLAM problem can be generalized as a Maximum A Posteriori (MAP)
estimation. Bayes Filter is then used to recursively perform the state
prediction and measurement update steps to minimizes linearization errors for
robust localization. In this case, MAP can be expressed as:
\begin{equation}
    P(X|Z, U) \propto P(x_0) \prod_{k} P(z_k|x_k) \prod_{k} P(x_k|x_{k-1}, u_{k-1})
\end{equation}

Where $P(X|Z, U)$ is the refined state estimate, $P(x_0)$ is the initial
condition, $P(z_k|x_k)$ is the sensor measurement and $P(x_k|x_{k-1}, u_{k-1})$
is the predicted state.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Included_Images/Kalman Filter.png}
    \caption{The red distribution in the figure represents the predicted state $x^f_k$ with its uncertainty $P^f_k$. The blue distribution represents the noisy sensor measurement $z_k$, and the green distribution illustrates the refined state estimate $x^a_k$ after the iterative update with the reduction of uncertainty covariance $P_k$ after fusing both data sources \cite{faragher2012understanding}.}
\end{figure}

\subsubsection{Graph-Based SLAM}
As LiDAR odometry does not include loop closure, iSAM2 pose graph optimization
architecture is used to optimize the point cloud map. This technique is rooted
from the factor graph optimization algorithm where the joint posterior
probability of the robot trajectory X is factorized based on the Maximum A Posteriori (MAP)estimate:

\begin{equation} 
    P(X|Z, U) \propto P(x_0) \prod_{k} P(z_k|x_k) \prod_{k} P(x_k|x_{k-1}, u_{k-1}) 
\end{equation}


 





% --- Experiments ---
\section{Experiments}
Placeholder text

\subsection{Experiment Workflow}
Placeholder text

\subsection{Summary of Experiments Conducted}
Placeholder text

\subsection{Key Experiment 1}
Placeholder text

\subsection{Key Experiment 2}
Placeholder text


% --- Results and Discussion ---
\section{Results and Discussion}
Placeholder text

\subsection{Path Planning}
Placeholder text

\subsection{GNSS-R}
Placeholder text

\subsection{Machine Learning}
Placeholder text

\subsection{LiDAR SLAM}
Placeholder text


% --- Conclusion ---
\section{Conclusion}
Placeholder text


% --- Future Works ---
\section{Future Works}
Placeholder text

\subsection{Path Planning}
Placeholder text

\subsection{GNSS-R}
Placeholder text

\subsection{Machine Learning}
Placeholder text

\subsection{LiDAR SLAM}
Placeholder text


% --- Project Management ---
\section{Project Management}
Placeholder text

\subsection{Gantt Chart}
Placeholder text

\subsection{Project Difficulties and Solutions}
Placeholder text

\subsubsection{Path Planning}
Placeholder text

\subsubsection{GNSS-R}
Placeholder text

\subsubsection{Machine Learning}
Placeholder text

\subsubsection{LiDAR SLAM}
Placeholder text


% --- Appendix ---
\newpage
\addcontentsline{toc}{section}{Appendix}
\section*{Appendix}
Placeholder text


% --- References ---
\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{IEEEtran}
\bibliography{References.bib} 


\end{document}